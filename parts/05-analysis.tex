\chapter{Описание предметной области}

\section{Задача поиска объекта на изображении}

Задача поиска объекта на изображении сводится к решению следующих подзадач~\cite{task}: 
\begin{enumerate}
	\item сегментация~--- выделение участков изображения, которые относятся к разным объектам;
	\item классификация~--- определение типа объекта, для каждого выделенного сегмента отдельно.
\end{enumerate}
Таким образом, обнаружение объектов~---~это процесс сегментации и классификации объектов в изображении.
Этот процесс представлен на рисунке~\ref{img:intro}.
\includeimage
	{intro}
	{f}
	{H}
	{1\textwidth}
	{Процесс сегментации и классификации объектов}

\section{Сверточные нейронные сети для поиска объектов на изображениях}

Сверточные нейронные сети являются наиболее распространенным алгоритмом глубокого обучения, применяющим несколько сверхточных слоев и вычислений.
Они предоставляют эффективные способы извлечения признаков, а также являются лучшим выбором для решения проблем обнаружения объектов.
Текущие подходы с использованием методов глубокого обучения для задач классификации и регрессии объектов можно разделить на две категории~\cite{base}:
\begin{enumerate}
	\item двухэтапные методы, которые представлены такими архитектурами, как R-CNN, Fast R-CNN и Faster R-CNN;
	\item одноэтапные методы, представленные различными версиями YOLO и др.
\end{enumerate}

Описанные методы представлены на рисунке~\ref{img:stages}.
\includeimage
	{stages}
	{f}
	{H}
	{1\textwidth}
	{Двухэтапный и одноэтапный методы}

\clearpage
В двухэтапных методах используется селективный поиск или сеть региональных предположений (англ. RPN) для выделения областей, с высокой вероятностью содержащих внутри себя объекты.
Затем, при помощи классификатора, определяется класс объекта, а при помощи регрессора определяются ограничивающие рамки.
Данный метод обладает высокой точностью, но при этом ограничен в скорости обнаружения.

Одноэтапные методы не используют отдельную сеть для генерации регионов и основываются на методах регрессии, просматривая изображения целиком.
Так как данные алгоритмы не используют RPN, скорость обнаружения выше, но точность выделения, в особенности малых объектов, не такая высокая, как у двухэтапных методов~\cite{base}.

\subsection{YOLO}

YOLO~---~сеть, предназначенная для идентификации и распознавания объектов на изображениях в реальном времени.
Такой подход к обнаружению объектов называется <<Вы смотрите только один раз>> (YOLO), что означает распознавание объектов сразу после первого прохода по изображению.
Метод YOLO рассматривает обнаружение объектов как задачу регрессии с пространственно разделенными ограничивающими рамками и соответствующими вероятностями классов, которые прогнозируются с помощью одной нейронной сети на основе полных изображений в ходе одной оценки.
YOLO быстра по своей конструкции и действительно работает в режиме реального времени, сохраняя большую точность~\cite{base, all}.

Базовая модель YOLO также называется YOLO версии 1 (YOLOv1).
Она решает задачу обнаружения объектов на изображении как задачу регрессии.
Одна сверточная сеть одновременно предсказывает множество ограничивающих рамок и вероятности классов для этих рамок.
YOLOv1 разбивает входное изображение на сетку $S \times S$.
Если центр объекта попадает в ячейку сетки, эта ячейка отвечает за обнаружение этого объекта.
Каждая ячейка сетки предсказывает $B$ ограничивающих рамок, показатели достоверности для этих рамок и вероятности класса $C$ для сетки.
Эти прогнозы закодированы в виде тензора $S \times S \times (B \times 5 + C)$.
В процессе тестирования YOLOv1 умножает условные вероятности классов и прогнозы достоверности отдельных блоков, которые дают оценки для каждого блока, относящиеся к конкретному классу по формуле~\ref{eq1}~\cite{all}.
\begin{equation}
	\label{eq1}
	Pr(Class_{i} | Object) \times Pr(Object) \times IOU^{truth}_{pred} = Pr(Class_{i}) \times IOU^{truth}_{pred}
\end{equation}

Оценки отражают вероятность появления этого класса в поле и схожесть поля с объектом.
Каждое ограничивающее поле состоит из 5 прогнозов: $x$, $y$, $w$, $h$ и достоверности.
Координаты $(x, y)$ представляют центр прямоугольника относительно границ ячейки сетки.
Ширина $w$ и высота $h$ рассчитываются относительно всего изображения.
Именно поэтому YOLOv1 использует выражение $B \times 5$ для вычисления тензора.
Сеть YOLOv1 состоит из 24 сверточных слоев, за которыми следуют 2 полностью соединенных слоя.
Вместо начальных модулей, используемых в GoogLeNet, YOLOv1 использует слой сокращения 1 $\times$ 1, за которым следуют сверточные слои 3 $\times$ 3.
В Pascal VOC2007 YOLOv1 обрабатывает изображения со скоростью 45 кадров в секунду (FPS), что в 2~---~9 раз быстрее, чем у Faster R-CNN.
В частности, Fast YOLO, быстрая версия YOLO, разработанная для расширения возможностей быстрого обнаружения объектов, достигает 155 кадров в секунду (FPS)~\cite{base, all}.

Архитектура YOLOv1 CNN представлена на рисунке~\ref{img:yolov1}.
\includeimage
	{yolov1}
	{f}
	{H}
	{1\textwidth}
	{Архитектура YOLOv1 CNN}

YOLO версии 2 (YOLOv2)~---~значительно улучшенная модель YOLO, которая сохраняет преимущество в скорости и пытается повысить качество распознавания по сравнению с YOLOv1.
Используя новый многомасштабный метод обучения, одна и та же модель YOLOv2 может работать в разных размерностях, предлагая простой компромисс между скоростью и качеством.
Алгоритм лучше справляется с небольшими объектами и реагирует быстрее, чем ранее доступные версии.
Одноступенчатая архитектура предполагает наличие только одной нейронной сети для прогнозирования ограничивающей рамки и вероятности категории.
YOLOv2 имеет множество улучшений по сравнению со своими предшественниками и другими алгоритмами.
В первую очередь, YOLOv2 использует Darknet-19 с 19 сверточными слоями и 5 слоями Max-Pooling и вводит якорные рамки (anchor boxes), что позволяет лучше адаптироваться к объектам разных размеров.
Вместо абсолютных значений координаты предсказываются как смещения относительно якорных рамок, для каждой из которых модель предсказывает параметры координат, уверенность и вероятности классов~\cite{yolochina, yolobase}.

Архитектура YOLOv2 CNN представлена на рисунке~\ref{img:yolov2}.
\includeimage
	{yolov2}
	{f}
	{H}
	{1\textwidth}
	{Архитектура YOLOv2 CNN}

\subsection{R-CNN}

В последнее время для решения задачи поиска объектов на изображении широкое распространение получили алгоритмы, основанные на применении региональных глубоких сверточных нейронных сетей или Regional Convolutional Neural Networks (R-CNN), которые принципиально ориентированы на решение задачи поиска объектов с одновременной их классификацией.
Исходная реализация таких моделей базируются на использовании специальных алгоритмов предобработки~---~алгоритмов region-proposal-function, обеспечивающих предложение так называемых областей внимания, в которых потенциально могут находиться интересующие объекты.
Описанный подход предлагает сократить вычислительные затраты, а также позволяют добиться минимального времени определения местоположения объекта и высокой точности его классификации.
К настоящему моменту имеется большое количество вариантов реализации подобных алгоритмов, которые достигли хороших показателей по данным критериям.
Алгоритм работы R-CNN состоит из следующих основных шагов~\cite{rcnn}:
\begin{enumerate}
	\item выполняется генерация областей интереса (region proposals), предположительно содержащих в себе искомые объекты (обычно до 2000 возможных областей) с использованием различных алгоритмов, предназначенных для снижения вычислительной сложности обнаружения объектов на изображении (например, алгоритмы Edge Boxes, Selective search);
	\item выполняется формирование карты признаков для исходного изображения путем аффинных преобразований, и каждая область интереса преобразуется в квадрат 227 $\times$ 227,	так как используемая архитектура CNN требует входы фиксированного размера 227 $\times$ 227	пикселей;
	\item выполняется классификация объектов для каждой области интереса с использованием сформированного вектора признаков на основе метода опорных векторов (SVM).
\end{enumerate}
Для оценки качества классификации, аналогично модели YOLO, используется показатель $IOU$.
Считается, что объект обнаружен правильно, если данный показатель превышает некоторый порог, в противном случае считается, что объект не обнаружен~\cite{yolochina, rcnn}.

\clearpage
Схема алгоритма работы R-CNN представлена на рисунке~\ref{img:rcnn}.
\includeimage
	{rcnn}
	{f}
	{H}
	{0.35\textwidth}
	{Схема алгоритма работы R-CNN}

Пример распознавания с использованием R-CNN представлен на рисунке~\ref{img:rcnnwork}.
\includeimage
	{rcnnwork}
	{f}
	{H}
	{1\textwidth}
	{Пример распознавания с использованием R-CNN}

\subsection{Fast R-CNN}

Модель Fast R-CNN является улучшением классической модели R-CNN, которая известна своей низкой производительностью, особенно при взаимодействии с более глубокими сетями.
Также, при использовании R-CNN затрачивается большой объем памяти для хранения данных.
Алгоритм работы Fast R-CNN состоит из следующих основных шагов~\cite{yolochina, rcnn}:
\begin{enumerate}
	\item аналогично R-CNN выполняется генерация областей интереса (region proposals);
	\item выполняется формирование карты признаков для исходного изображения, но, в отличие от R-CNN, на вход нейронной сети CNN подается полное исходное изображение с последним слоем RoI pooling вместо Max pooling;
	\item выполняется уточнение границ области интереса при помощи регрессионной модели (Bounding Box Regression);
	\item выполняется классификация объектов, содержащихся в предполагаемых областях интереса с использованием слоя softmax с $K+1$ выходами.
\end{enumerate}

\clearpage
Схема алгоритма работы Fast R-CNN представлена на рисунке~\ref{img:fastrcnn}.
\includeimage
	{fastrcnn}
	{f}
	{H}
	{0.3\textwidth}
	{Схема алгоритма работы Fast R-CNN}

Пример распознавания с использованием Fast R-CNN представлен на рисунке~\ref{img:fastrcnnwork}.
\includeimage
	{fastrcnnwork}
	{f}
	{H}
	{1\textwidth}
	{Пример распознавания с использованием Fast R-CNN}

\clearpage

\subsection{Faster R-CNN}

Faster R-CNN представила сеть региональных предложений (RPN), основанную на Fast R-CNN, которая заменяет внешний алгоритм для генерации областей интереса, предположительно содержащих объект.
Области интереса (region proposals) используют такую информацию, как текстура, границы и цвет изображения, чтобы заранее определить положение, в котором может появиться искомый объект, что может гарантировать более высокую скорость отклика при меньшем количестве выбранных окон (несколько сотен или даже несколько тысяч).
Такой подход значительно сокращает временные затраты на последующие операции и позволяет получить искомое окно, а не скользящее более высокого качества.
В некотором смысле, Faster R-CNN можно представить в виде объединения RPN и Fast R-CNN.
Эта модификация R-CNN уже предоставила результат с эталонной точностью распознавания, поэтому единственным улучшением будет являться скорость работы, что является основной причиной появления более поздних алгоритмов~\cite{fasterrcnn}.

Алгоритм работы Faster R-CNN состоит из следующих основных шагов~\cite{yolochina, rcnn, fasterrcnn}:
\begin{enumerate}
	\item выполняется формирование карты признаков на основе исходного изображения при помощи CNN;
	\item выполняется генерация областей интереса, возможно содержащих объект, за счет обработки скользящим окном размера 3 $\times$ 3 сформированной карты признаков с использованием RPN;
	\item выполняется преобразование вектора признаков области интереса из исходного изображения в вектор признаков фиксированной размерности с помощью слоя RoI pooling;
	\item аналогично шагу 3 алгоритма работы Fast R-CNN выполняется уточнение границ области интереса;
	\item аналогично шагу 4 алгоритма работы Fast R-CNN выполняется классификация объектов, содержащихся в предполагаемых областях интереса.
\end{enumerate}

\clearpage
Схема алгоритма работы Faster R-CNN представлена на рисунке~\ref{img:fasterrcnn}.
\includeimage
	{fasterrcnn}
	{f}
	{H}
	{0.25\textwidth}
	{Схема алгоритма работы Faster R-CNN}

Пример распознавания с использованием Faster R-CNN представлен на рисунке~\ref{img:fasterrcnnwork}.
\includeimage
	{fasterrcnnwork}
	{f}
	{H}
	{1\textwidth}
	{Пример распознавания с использованием Faster R-CNN}
