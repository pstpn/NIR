\subsection{YOLO}

YOLO~---~сеть, предназначенная для идентификации и распознавания объектов на изображениях в реальном времени.
Такой подход к обнаружению объектов называется <<Вы смотрите только один раз>> (YOLO), что означает распознавание объектов сразу после первого прохода по изображению.
Метод YOLO рассматривает обнаружение объектов как задачу регрессии с пространственно разделенными ограничивающими рамками и соответствующими вероятностями классов, которые прогнозируются с помощью одной нейронной сети на основе полных изображений в ходе одной оценки.
YOLO быстра по своей конструкции и действительно работает в режиме реального времени, сохраняя большую точность~\cite{base, all}.

Базовая модель YOLO также называется YOLO версии 1 (YOLOv1).
Она решает задачу обнаружения объектов на изображении как задачу регрессии.
Одна сверточная сеть одновременно предсказывает множество ограничивающих рамок и вероятности классов для этих рамок.
YOLOv1 разбивает входное изображение на сетку $S \times S$.
Если центр объекта попадает в ячейку сетки, эта ячейка отвечает за обнаружение этого объекта.
Каждая ячейка сетки предсказывает $B$ ограничивающих рамок, показатели достоверности для этих рамок и вероятности класса $C$ для сетки.
Эти прогнозы закодированы в виде тензора $S \times S \times (B \times 5 + C)$.
В процессе тестирования YOLOv1 умножает условные вероятности классов и прогнозы достоверности отдельных блоков, которые дают оценки для каждого блока, относящиеся к конкретному классу по формуле~\ref{eq1}~\cite{all}.
\begin{equation}
	\label{eq1}
	Pr(Class_{i} | Object) \times Pr(Object) \times IOU^{truth}_{pred} = Pr(Class_{i}) \times IOU^{truth}_{pred}
\end{equation}

Оценки отражают вероятность появления этого класса в поле и схожесть поля с объектом.
Каждое ограничивающее поле состоит из 5 прогнозов: $x$, $y$, $w$, $h$ и достоверности.
Координаты $(x, y)$ представляют центр прямоугольника относительно границ ячейки сетки.
Ширина $w$ и высота $h$ рассчитываются относительно всего изображения.
Именно поэтому YOLOv1 использует выражение $B \times 5$ для вычисления тензора.
Сеть YOLOv1 состоит из 24 сверточных слоев, за которыми следуют 2 полностью соединенных слоя.
Вместо начальных модулей, используемых в GoogLeNet, YOLOv1 использует слой сокращения 1 $\times$ 1, за которым следуют сверточные слои 3 $\times$ 3.
В Pascal VOC2007 YOLOv1 обрабатывает изображения со скоростью 45 кадров в секунду (FPS), что в 2~---~9 раз быстрее, чем у Faster R-CNN.
В частности, Fast YOLO, быстрая версия YOLO, разработанная для расширения возможностей быстрого обнаружения объектов, достигает 155 кадров в секунду (FPS)~\cite{base, all}.

Архитектура YOLOv1 CNN представлена на рисунке~\ref{img:yolov1}.
\includeimage
	{yolov1}
	{f}
	{H}
	{1\textwidth}
	{Архитектура YOLOv1 CNN}

YOLO версии 2 (YOLOv2)~---~значительно улучшенная модель YOLO, которая сохраняет преимущество в скорости и пытается повысить качество распознавания по сравнению с YOLOv1.
Используя новый многомасштабный метод обучения, одна и та же модель YOLOv2 может работать в разных размерностях, предлагая простой компромисс между скоростью и качеством.
Алгоритм лучше справляется с небольшими объектами и реагирует быстрее, чем ранее доступные версии.
Одноступенчатая архитектура предполагает наличие только одной нейронной сети для прогнозирования ограничивающей рамки и вероятности категории.
YOLOv2 имеет множество улучшений по сравнению со своими предшественниками и другими алгоритмами.
В первую очередь, YOLOv2 использует Darknet-19 с 19 сверточными слоями и 5 слоями Max-Pooling и вводит якорные рамки (anchor boxes), что позволяет лучше адаптироваться к объектам разных размеров.
Вместо абсолютных значений координаты предсказываются как смещения относительно якорных рамок, для каждой из которых модель предсказывает параметры координат, уверенность и вероятности классов~\cite{yolochina, yolobase}.

Архитектура YOLOv2 CNN представлена на рисунке~\ref{img:yolov2}.
\includeimage
	{yolov2}
	{f}
	{H}
	{1\textwidth}
	{Архитектура YOLOv2 CNN}

\subsection{R-CNN}

В последнее время для решения задачи поиска объектов на изображении широкое распространение получили алгоритмы, основанные на применении региональных глубоких сверточных нейронных сетей или Regional Convolutional Neural Networks (R-CNN), которые принципиально ориентированы на решение задачи поиска объектов с одновременной их классификацией.
Исходная реализация таких моделей базируются на использовании специальных алгоритмов предобработки~---~алгоритмов region-proposal-function, обеспечивающих предложение так называемых областей внимания, в которых потенциально могут находиться интересующие объекты.
Описанный подход предлагает сократить вычислительные затраты, а также позволяют добиться минимального времени определения местоположения объекта и высокой точности его классификации.
К настоящему моменту имеется большое количество вариантов реализации подобных алгоритмов, которые достигли хороших показателей по данным критериям~\cite{rcnn}.

Алгоритм работы R-CNN состоит из следующих основных шагов:
\begin{enumerate}
	\item выполняется генерация областей интереса (region proposals), предположительно содержащих в себе искомые объекты (обычно до 2000 возможных областей) с использованием различных алгоритмов, предназначенных для снижения вычислительной сложности обнаружения объектов на изображении (например, алгоритмы Edge Boxes, Selective search);
	\item выполняется формирование карты признаков для исходного изображения путем аффинных преобразований, и каждая область интереса преобразуется в квадрат 227 $\times$ 227,	так как используемая архитектура CNN требует входы фиксированного размера 227 $\times$ 227	пикселей;
	\item выполняется классификация объектов для каждой области интереса с использованием сформированного вектора признаков на основе метода опорных векторов (SVM).
\end{enumerate}
Для оценки качества классификации, аналогично модели YOLO, используется показатель $IOU$.
Считается, что объект обнаружен правильно, если данный показатель превышает некоторый порог, в противном случае считается, что объект не обнаружен~\cite{yolochina, rcnn}.

Схема алгоритма работы R-CNN представлен на рисунке~\ref{img:rcnn}.
\includeimage
	{rcnn}
	{f}
	{H}
	{0.5\textwidth}
	{Схема алгоритма работы R-CNN}

Пример распознавания с использованием R-CNN представлен на рисунке~\ref{img:rcnnwork}.
\includeimage
	{rcnnwork}
	{f}
	{H}
	{1\textwidth}
	{Пример распознавания с использованием R-CNN}

\subsection{Fast R-CNN}

Модель Fast R-CNN является улучшением классической модели R-CNN, которая известна своей низкой производительностью, особенно при взаимодействии с более глубокими сетями.
Также, при использовании R-CNN затрачивается большой объем памяти для хранения данных.

Алгоритм работы Fast R-CNN состоит из следующих основных шагов~\cite{yolochina, rcnn}:
\begin{enumerate}
	\item аналогично R-CNN выполняется генерация областей интереса (region proposals);
	\item выполняется формирование карты признаков для исходного изображения, но, в отличие от R-CNN, на вход нейронной сети CNN подается полное исходное изображение с последним слоем RoI pooling вместо Max pooling;
	\item выполняется уточнение границ области интереса при помощи регрессионной модели (Bounding Box Regression);
	\item выполняется классификация объектов, содержащихся в предполагаемых областях интереса с использованием слоя softmax с $K+1$ выходами.
\end{enumerate}

\clearpage
Схема алгоритма работы Fast R-CNN представлен на рисунке~\ref{img:fastrcnn}.
\includeimage
	{fastrcnn}
	{f}
	{H}
	{1\textwidth}
	{Схема алгоритма работы Fast R-CNN}

Пример распознавания с использованием Fast R-CNN представлен на рисунке~\ref{img:fastrcnnwork}.
\includeimage
	{fastrcnnwork}
	{f}
	{H}
	{1\textwidth}
	{Пример распознавания с использованием Fast R-CNN}

\clearpage

\subsection{Faster R-CNN}